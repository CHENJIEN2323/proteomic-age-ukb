{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import miceforest as mf\n",
    "\n",
    "now = dt.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d')\n",
    "filepath = '/Users/aargenti/Documents/proteomic_age/'\n",
    "random_seed = 3456\n",
    "\n",
    "#Load protein data (our file is columns for eid, plate, batch, and all olink proteins)\n",
    "data_path2 = f'{filepath}data/olink_data_wide_oct_30_2023.csv'\n",
    "data = pd.read_csv(data_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names with missing data over 30.0%: Index(['GLIPR1', 'NPM1', 'PCOLCE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Calculate the threshold for missing data\n",
    "perc = 0.3\n",
    "threshold = perc * len(data)\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "mperc = (data.isnull().sum() / len(data)) * 100\n",
    "\n",
    "# Filter columns where missing data is over 30%\n",
    "cols_over = mperc[mperc > (perc*100)].index\n",
    "\n",
    "print(f\"Column names with missing data over {perc*100}%: {cols_over}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dictionary of variables use to impute\n",
    "\n",
    "# columns that should not be used to impute missing (including 3 proteins with high missing)\n",
    "exclude = ['eid', 'olink_batch', 'olink_plate', 'GLIPR1', 'NPM1', 'PCOLCE']\n",
    "# variables we don't want imputed\n",
    "dont_impute = ['eid', 'olink_batch', 'olink_plate']\n",
    "# create dict with list of predictors for each protein\n",
    "column_dict = {col: [other_col for other_col in data.columns if other_col != col and other_col not in exclude] for col in data.columns if col not in dont_impute}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run miceforest imputation on multiple cores\n",
    "kds = mf.ImputationKernel(\n",
    "  data,\n",
    "  datasets=1,\n",
    "  variable_schema=column_dict,\n",
    "  random_state=random_seed\n",
    ")\n",
    "\n",
    "# run\n",
    "kds.mice(\n",
    "  iterations=5,\n",
    "  n_jobs=-1, \n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the completed dataframe from the miceforest object\n",
    "olink_data_imputed = kds.complete_data()\n",
    "\n",
    "#save imputed data\n",
    "olink_data_imputed.to_csv(f'{filepath}data/olink_data_wide_june_22_2023_imputed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protAge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
